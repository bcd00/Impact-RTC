{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from utilities.data_processing.caching import load\n",
    "from utilities.utils import check_network, env_bool, load_db, shared_dir\n",
    "from utilities.data_processing.processing_utils import augment_dataframe, get_place_annotation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial Setup\n",
    "\n",
    "Load database connection, determine whether to load from cache, basic setup of global configurations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_cache = not check_network() or env_bool('USE_CACHE')\n",
    "print(f'Using Cache: {use_cache}')\n",
    "db = load_db() if not use_cache else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data\n",
    "\n",
    "Loads data from cache and remote, saving records fetched from remote to the cache."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets, users, places, locations = load(db, use_cache)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Format Data\n",
    "\n",
    "Basic formatting, merging tweets with users, places and locations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_level_keys = ['author_id', 'context_annotations', 'created_at', 'geo', 'id', 'lang', 'non_public_metrics',\n",
    "                  'possibly_sensitive', 'text', 'entities']\n",
    "second_level_keys = [('public_metrics', 'retweet_count'), ('public_metrics', 'reply_count'),\n",
    "                     ('public_metrics', 'like_count'), ('public_metrics', 'quote_count')]\n",
    "\n",
    "print('Augmenting Top-Level Keys')\n",
    "for key in tqdm(top_level_keys):\n",
    "    tweets = augment_dataframe(tweets, key)\n",
    "\n",
    "print('Augmenting Second-Level Keys')\n",
    "for key in tqdm(second_level_keys):\n",
    "    tweets = augment_dataframe(tweets, *key)\n",
    "\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Processing Rules')\n",
    "tweets['rules'] = tweets['matching_rules'].progress_apply(lambda xs: [x['tag'] for x in xs])\n",
    "tweets.drop('matching_rules', axis=1, inplace=True)\n",
    "\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets.drop(['data', '_id', 'context_annotations', 'possibly_sensitive', 'non_public_metrics', 'lang', 'retweet_count', 'reply_count', 'like_count', 'quote_count', 'includes'], axis=1, inplace=True)\n",
    "tweets.drop_duplicates(subset='id', inplace=True)\n",
    "tweets.drop_duplicates(subset='text', inplace=True)\n",
    "tweets.set_index('id', inplace=True)\n",
    "\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets['place_id'] = tweets['geo'].apply(lambda x: x.get('place_id', np.nan))\n",
    "tweets[~(tweets['geo'].str.len() != 2)].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users.drop('_id', axis=1, inplace=True)\n",
    "users.set_index('user_id', inplace=True)\n",
    "users.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "places.drop('_id', axis=1, inplace=True)\n",
    "places.set_index('place_id', inplace=True)\n",
    "places.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets = tweets.merge(users, how='left', left_on='author_id', right_index=True, suffixes=(None, '_user'))\n",
    "tweets = tweets.merge(places, how='left', left_on='place_id', right_index=True, suffixes=(None, '_place'))\n",
    "del users, places\n",
    "\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets.rename(columns={'data': 'user_data', 'data_place': 'place_data'}, inplace=True)\n",
    "\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Format Location\n",
    "\n",
    "Formats places from raw JSON."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets[tweets['place_id'].str.len() > 3].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets['user_location'] = tweets['user_data'].apply(\n",
    "    lambda x: x.get('data', {}).get('location', '') if isinstance(x, dict) else '')\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets[~(tweets['entities'].str.len() == 0 & tweets['entities'].isnull())]['entities'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Loading Annotations')\n",
    "tweets['entities_places'] = tweets['entities'].progress_apply(get_place_annotation)\n",
    "tweets[tweets['entities_places'].str.len() > 2]['entities_places'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index().merge(locations, how='left', left_on='user_location', right_on='key', suffixes=(None, '_user_location')).set_index('id')\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "locations_series = locations.set_index('key')['value']\n",
    "print('Resolving Entity Locations')\n",
    "tweets['entity_locations'] = tweets['entities_places'].progress_apply(\n",
    "    lambda x: [locations_series.get(entity['normalized_text'], None) for entity in x])\n",
    "del locations, locations_series\n",
    "tweets[tweets['entity_locations'].str.len() > 2]['entity_locations'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Data\n",
    "\n",
    "Saves data to a pickle file at './output/shared/tweets.pickle' for use in the geospatial_processing notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets.to_pickle(f'{shared_dir}/tweets.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}