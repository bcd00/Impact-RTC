{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.core.display_functions import display\n",
    "from utilities.classifier.nlp_model import NLPModel\n",
    "from utilities.data_processing.preprocessing import PreProcessing\n",
    "from utilities.classifier.model_utils import run_graph, preprocessing_graph, augmentation_graph, \\\n",
    "    run_cross_validation, display_cross_validation, update_key\n",
    "from utilities.utils import shared_dir, read_json, annotated_dir, read_jsonl, \\\n",
    "    calculate_dataset_similarity, get_positive, get_negative, plot_confusion_matrix, hashtags_dir, \\\n",
    "    input_dir, kappa, get_cuda_availability, load_raw_annotations, annotations_dir, classifier_tuning_dir, \\\n",
    "    final_model_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "DEVICE = get_cuda_availability()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and pre-process labelled dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labelled = pd.read_pickle(f'{shared_dir}/labelled.pickle')\n",
    "\n",
    "labelled['label'] = labelled['label'].astype(int)\n",
    "labelled_raw = labelled.copy()\n",
    "\n",
    "print(f'Size of labelled data: {len(labelled)}')\n",
    "labelled.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = PreProcessing(labelled, word_source=f'{hashtags_dir}/50_000_words.txt')\n",
    "preprocessing.strip_newlines().contextualise_hashtags(cache_source=f'{hashtags_dir}/unigram_hashtags_50_000.json', use_frequencies=True).emojis()\n",
    "labelled = preprocessing.df\n",
    "labelled.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and pre-process external test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_data = pd.DataFrame(read_jsonl(f'{annotated_dir}/annotations/10k_sample_tweets.jsonl'))\n",
    "original_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotated_data = pd.DataFrame(read_json(f'{annotated_dir}/annotations/annotated_10k_sample_tweets.json'))\n",
    "annotated_data = annotated_data[~(annotated_data['answer'] == 'ignore')]\n",
    "\n",
    "annotated_data['text'] = original_data['text']\n",
    "annotated_data['label'] = annotated_data['answer'].progress_apply(lambda x: 0 if x == 'reject' else 1)\n",
    "\n",
    "annotated_data.drop('id', axis=1, inplace=True)\n",
    "annotated_data.drop('accept', axis=1, inplace=True)\n",
    "annotated_data.drop('spans', axis=1, inplace=True)\n",
    "annotated_data.drop('answer', axis=1, inplace=True)\n",
    "annotated_data_raw = annotated_data.copy()\n",
    "\n",
    "annotated_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessor = PreProcessing(annotated_data, word_source=f'{hashtags_dir}/50_000_words.txt')\n",
    "preprocessor.strip_newlines().contextualise_hashtags(cache_source=f'{hashtags_dir}/unigram_hashtags_50_000.json', use_frequencies=True).emojis()\n",
    "annotated_data = preprocessor.df\n",
    "annotated_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Jaccard similarity between the classes of the labelled and external datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f'{shared_dir}/tokenizer/')\n",
    "overall_similarity = calculate_dataset_similarity(tokenizer, labelled, annotated_data)\n",
    "pp_similarity = calculate_dataset_similarity(tokenizer, get_positive(labelled), get_positive(annotated_data))\n",
    "nn_similarity = calculate_dataset_similarity(tokenizer, get_negative(labelled), get_negative(annotated_data))\n",
    "pn_similarity = calculate_dataset_similarity(tokenizer, get_positive(labelled), get_negative(annotated_data))\n",
    "np_similarity = calculate_dataset_similarity(tokenizer, get_negative(labelled), get_positive(annotated_data))\n",
    "\n",
    "print(f'Overall similarity of training and testing data: {overall_similarity}')\n",
    "plot_confusion_matrix(np.asarray([nn_similarity, pn_similarity, np_similarity, pp_similarity]).reshape((2, 2)),\n",
    "                      filename=f'{annotations_dir}/jaccard_similarity', format_labels=False, group_names=['NN', 'PN', 'NP', 'PP'])\n",
    "del tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate annotator agreement and Cohen's kappa\n",
    "$ CK = \\frac{2 * (TP * TN - FN * FP)}{(TP + FP) * (FP + TN) + (TP + FN) * (FN + TN)} $"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unzipped_annotations = load_raw_annotations(filename=f'{input_dir}/cross_annotations.json')\n",
    "\n",
    "cross_df = pd.DataFrame(\n",
    "    {'id': unzipped_annotations[0], 'text': unzipped_annotations[1], 'label': unzipped_annotations[2]})\n",
    "cross_df.set_index('id', inplace=True)\n",
    "cross_df['label'].astype(int)\n",
    "cross_df = annotated_data.merge(cross_df, how='right', left_index=True, right_index=True, suffixes=(None, '_annotation'))\n",
    "cross_df.drop(['text_annotation'], axis=1, inplace=True)\n",
    "cross_df.rename(columns={'label': 'annotator_two', 'label_annotation': 'annotator_one'}, inplace=True)\n",
    "\n",
    "cross_pp = len(cross_df[(cross_df.annotator_one == 1) & (cross_df.annotator_two == 1)])\n",
    "cross_nn = len(cross_df[(cross_df.annotator_one == 0) & (cross_df.annotator_two == 0)])\n",
    "cross_pn = len(cross_df[(cross_df.annotator_one == 1) & (cross_df.annotator_two == 0)])\n",
    "cross_np = len(cross_df[(cross_df.annotator_one == 0) & (cross_df.annotator_two == 1)])\n",
    "plot_confusion_matrix(np.asarray([cross_nn, cross_pn, cross_np, cross_pp]).reshape((2, 2)),\n",
    "                      filename=f'{annotations_dir}/annotator_agreement_test', group_names=['TN', 'FP', 'FN', 'TP'])\n",
    "print(kappa(cross_pp, cross_nn, cross_pn, cross_np))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save processed datasets for future use/visualisation purposes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "annotated_data.to_pickle(f'{shared_dir}/tedf.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "k = 5\n",
    "hyperparameters = read_json(f'{input_dir}/hyperparameters.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune initial learning rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['initial_lrs'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    update_key_=update_key,\n",
    "    x_key='lr_start',\n",
    "    x_title='Initial Learning Rate',\n",
    "    log_x=True,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/lr_start/lr_start_results.pickle'),\n",
    "    show_all=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune final learning rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['final_lrs'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='lr_end',\n",
    "    x_title='Final Learning Rate',\n",
    "    log_x=True,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/lr_end/lr_end_results.pickle'),\n",
    "    show_all=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune batch size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['batch_sizes'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='batch_size',\n",
    "    x_title='Batch Size',\n",
    "    log_x=False,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/batch_size/batch_size_results.pickle'),\n",
    "    show_all=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune model name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['model_types'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='model_name',\n",
    "    x_title='Model Name',\n",
    "    log_x=False,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/model_name/model_name_results.pickle'),\n",
    "    show_all=False\n",
    ")\n",
    "display(pd.read_pickle(f'{classifier_tuning_dir}/model_name/model_name_results.pickle').head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune number of epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['epochs'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='epochs',\n",
    "    x_title='No. Epochs',\n",
    "    log_x=False,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/epochs/epochs_results.pickle'),\n",
    "    show_all=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune scheduler type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['scheduler_types'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='scheduler_type',\n",
    "    x_title='Scheduler Type',\n",
    "    log_x=False,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/scheduler_type/scheduler_type_results.pickle'),\n",
    "    show_all=False\n",
    ")\n",
    "display(pd.read_pickle(f'{classifier_tuning_dir}/scheduler_type/scheduler_type_results.pickle').head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune use of downsampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    k=k,\n",
    "    xs=hyperparameters['downsampling'],\n",
    "    data=labelled,\n",
    "    tedf=annotated_data,\n",
    "    x_key='downsample',\n",
    "    x_title='Use Downsampling',\n",
    "    log_x=False,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/downsample/downsample_results.pickle'),\n",
    "    show_all=False\n",
    ")\n",
    "display(pd.read_pickle(f'{classifier_tuning_dir}/downsample/downsample_results.pickle').head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune pre-processing tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing_graph(\n",
    "    k=k,\n",
    "    data=labelled_raw,\n",
    "    testing=annotated_data_raw,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/preprocessing/preprocessing_results.pickle'),\n",
    "    baseline=pd.read_pickle(f'{classifier_tuning_dir}/baseline/baseline_results.pickle'),\n",
    "    show_all=False\n",
    ")\n",
    "display(pd.read_pickle(f'{classifier_tuning_dir}/baseline/baseline_results.pickle').head())\n",
    "display(pd.read_pickle(f'{classifier_tuning_dir}/preprocessing/preprocessing_results.pickle'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune use of augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "augmentation_graph(\n",
    "    k=k,\n",
    "    augmentation=hyperparameters['augmentation'],\n",
    "    data=labelled_raw,\n",
    "    tedf=annotated_data_raw,\n",
    "    device=DEVICE,\n",
    "    df=pd.read_pickle(f'{classifier_tuning_dir}/augmentation/augmentation_results.pickle'),\n",
    "    show_all=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run cross-validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "result = run_cross_validation(\n",
    "    k,\n",
    "    labelled,\n",
    "    annotated_data,\n",
    "    DEVICE,\n",
    "    key=None,\n",
    "    to_display=True,\n",
    "    cache=read_json(f'{final_model_dir}/cross_validation_results.json')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display cross-validation results for all datasets\n",
    "\n",
    "Datasets:\n",
    "<ul>\n",
    "    <li>Validation Dataset</li>\n",
    "    <li>Short Validation Dataset</li>\n",
    "    <li>Long Validation Dataset</li>\n",
    "    <li>Testing Dataset</li>\n",
    "    <li>Short Testing Dataset</li>\n",
    "    <li>Long Testing Dataset</li>\n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'eval',\n",
    "    cv_filename='validation/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/validation/cfm.png',\n",
    "    loss_filename=f'validation/losses',\n",
    "    lr_filename=f'validation/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/validation/predictions.txt',\n",
    "    display_training=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'short_eval',\n",
    "    cv_filename='short_validation/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/short_validation/cfm.png',\n",
    "    loss_filename=f'short_validation/losses',\n",
    "    lr_filename=f'short_validation/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/short_validation/predictions.txt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'long_eval',\n",
    "    cv_filename='long_validation/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/long_validation/cfm.png',\n",
    "    loss_filename=f'long_validation/losses',\n",
    "    lr_filename=f'long_validation/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/long_validation/predictions.txt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'test',\n",
    "    cv_filename='testing/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/testing/cfm.png',\n",
    "    loss_filename=f'testing/losses',\n",
    "    lr_filename=f'testing/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/testing/predictions.txt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'short_test',\n",
    "    cv_filename='short_testing/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/short_testing/cfm.png',\n",
    "    loss_filename=f'short_testing/losses',\n",
    "    lr_filename=f'short_testing/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/short_testing/predictions.txt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_cross_validation(\n",
    "    labelled,\n",
    "    result,\n",
    "    'long_test',\n",
    "    cv_filename='long_testing/cross_validation',\n",
    "    cfm_filename=f'{final_model_dir}/long_testing/cfm.png',\n",
    "    loss_filename=f'long_testing/losses',\n",
    "    lr_filename=f'long_testing/lrs',\n",
    "    predictions_filename=f'{final_model_dir}/long_testing/predictions.txt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Label all data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build and train final model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = NLPModel(\n",
    "    training_data=labelled,\n",
    "    validation_data=pd.DataFrame({'text': [], 'label': []}),\n",
    "    device=DEVICE,\n",
    "    use_downsampling=True,\n",
    "    batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    epochs=2,\n",
    "    scheduler_type='linear',\n",
    "    model_name='roberta-base'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train(log_level='critical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model and tokenizer to file for future use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save_pretrained(f'{shared_dir}/model/')\n",
    "model.tokenizer.save_pretrained(f'{shared_dir}/tokenizer/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and pre-process unlabelled geospatial data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "geo_df = pd.read_pickle(f'{shared_dir}/geospatial.pickle')\n",
    "print(f'Size of Geospatial Dataset: {len(geo_df)}')\n",
    "geo_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessor = PreProcessing(geo_df, word_source=f'{hashtags_dir}/50_000_words.txt')\n",
    "preprocessor.strip_newlines().contextualise_hashtags(cache_source=f'{hashtags_dir}/unigram_hashtags_50_000.json', use_frequencies=True).emojis()\n",
    "geo_df = preprocessor.df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label and format data for clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_df = model.fit(geo_df)\n",
    "display(cluster_df)\n",
    "cluster_df = cluster_df[cluster_df.label == 1].copy()\n",
    "cluster_df['id'] = cluster_df.index\n",
    "cluster_df.drop_duplicates(subset='id', inplace=True)\n",
    "cluster_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save clustering dataset to file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_df.to_pickle(f'{shared_dir}/clusters.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}